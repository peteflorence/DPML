\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\newlabel{lam_0}{{1}{1}{Results on different dataset for $\lambda = 0$}{table.1}{}}
\newlabel{stdev1_val_lam_0}{{1}{1}{$\lambda = 0$, stdev1 validation dataset}{figure.1}{}}
\newlabel{stdev4_train_lam_0}{{2}{1}{$\lambda = 0$, stdev4 train dataset}{figure.2}{}}
\newlabel{stdev4_val_lam_0}{{3}{2}{$\lambda = 0$, stdev4 validation dataset}{figure.3}{}}
\newlabel{nonsep_train_lam_0}{{4}{2}{$\lambda = 0$, nonsep train dataset}{figure.4}{}}
\newlabel{nonsep_train_lam_10}{{5}{2}{$\lambda = 10$, nonsep train dataset}{figure.5}{}}
\newlabel{nonsep_train_lam_100}{{6}{2}{$\lambda = 100$, nonsep train dataset}{figure.6}{}}
\newlabel{w_lam_norm}{{2}{2}{Norm of $\tilde {w}(\lambda )$ for different values of $\lambda $ on nonsep train dataset}{table.2}{}}
\newlabel{nonsep_train_lam_1000}{{7}{3}{$\lambda = 1000$, nonsep train dataset}{figure.7}{}}
\newlabel{C_0}{{3}{3}{SVM misclassification rates on different datasets for $C$=0}{table.3}{}}
\newlabel{svm_stdev1}{{8}{4}{Soft-SVM solution for decision boundary of "stdev1" training dataset with $C=1$ and a linear kernel. 'X' marks support vectors that are on the margin, whereas the triangle marks support vectors that are inside the margin}{figure.8}{}}
\newlabel{svm_stdev2}{{9}{4}{Soft-SVM solution for decision boundary of "stdev2" training dataset with $C=1$ and a linear kernel. 'X' marks support vectors that are on the margin, whereas the triangle marks support vectors that are inside the margin}{figure.9}{}}
\newlabel{svm_nonsep}{{10}{4}{Soft-SVM solution for decision boundary of "nonsep" validation dataset with $C=1$ and a linear kernel}{figure.10}{}}
\newlabel{geom_lin}{{11}{4}{Geometric margin for 40 values of C between .001 and 500. Computed with a linear kernel SVM}{figure.11}{}}
\newlabel{geom_gauss}{{12}{4}{Geometric margin for 40 values of C between .001 and 500. Computed with a Gaussian kernel SVM, $\sigma =1$}{figure.12}{}}
\newlabel{highC}{{13}{5}{Soft-SVM solution for decision boundary of "stdev1" training dataset with $C=1e9$ and a linear kernel. 'X' marks support vectors that are on the margin, whereas the triangle marks support vectors that are inside the margin}{figure.13}{}}
\newlabel{supportvectors}{{14}{5}{Number of support vectors as a function of $C$ for various values the range $[0.0001, 500]$ Computed with a Gaussian kernel SVM, $\sigma =1$}{figure.14}{}}
\newlabel{cer_svm}{{15}{5}{Classification error rates on the validation data sets, as a function of C for various values in the range $[0.0001, 500]$ Computed with a Gaussian kernel SVM, $\sigma =1$}{figure.15}{}}
\newlabel{nonsep_gaussian}{{16}{5}{Gaussian-kernel SVM ($C=\sigma =1$) able to nicely separate the validation data for the ``nonsep'' dataset. Classification error rate is 0.0475}{figure.16}{}}
\newlabel{bandwidth_cer}{{17}{6}{Validation datasets misclassification rates for various bandwidths, $\sigma $. Gaussian kernel and $C=1$ are used}{figure.17}{}}
\newlabel{titanic_logit}{{18}{6}{Results of logistic regression classifier on the Titanic dataset for different value of $\lambda $}{figure.18}{}}
\newlabel{titanic_svm}{{19}{6}{Results of the linear-kernel SVM classifier on the Titanic dataset for different value of $C$}{figure.19}{}}
\newlabel{weights}{{4}{6}{Classification weights}{table.4}{}}
